# Hacking on oshinko-rest

This document covers some common tips and tricks for developing, debugging,
and extending the oshinko-rest application.

### Using server-ui-template.yaml directly

The `tools` directory contains a template for launching the
oshinko application with default public images. The simplest way to use
this template is via the `oshinko-deploy.sh` script described below.

If you use the template directly, you will have to first manually create the oshinko
service account. For example, in the project *myproject* do this:

    $ oc create sa oshinko
    $ oc policy add-role-to-user admin system:serviceaccount:myproject:oshinko

Then launch the template

    $ oc process -f tools/server-ui-template.yaml | oc create -f -

## Overriding default images in the server-ui-template.yaml

There are several parameters in `server-ui-template.yaml` that may be set to launch oshinko
using alternate images:

* OSHINKO_SERVER_IMAGE  -- the oshinko-rest image (required, defaulted)
* OSHINKO_CLUSTER_IMAGE -- the spark image used by oshinko-rest to create clusters (not required)
* OSHINKO_WEB_IMAGE     -- the oshinko-webui image (required, defaulted)

Note that the oshinko-rest image already contains a default setting
for which spark image to use, so the OSHINKO_CLUSTER_IMAGE parameter
in the template is initially blank.

Example using images which have been pushed to the integrated registry at
172.30.159.57:5000 for project "myproject":

    $ oc process -f tools/server-ui-template.yaml -v OSHINKO_SERVER_IMAGE=172.30.159.57:5000/myproject/oshinko-rest,OSHINKO_CLUSTER_IMAGE=172.30.159.57:5000/myproject/openshift-spark,OSHINKO_WEB_IMAGE=172.30.159.57:5000/myproject/oshinko-webui > server-template.json
    $ oc create -f server-template.json

### Producing a version of server-ui-template.yaml for a particular release

Tagged images are produced for oshinko-rest and oshinko-webui with each
oshinko release. If you want to create a server-ui-template.yaml that uses
images from a particular release, you can run the `release-templates.sh` script
to create it. For example:

    $ ./tools/release-templates.sh v0.2.6
    Successfully wrote templates to release_templates/ with version tag v0.2.6

    grep radanalyticsio/oshinko-.*:v0.2.6 *

    value: radanalyticsio/oshinko-rest:v0.2.6
    value: radanalyticsio/oshinko-webui:v0.2.6

The new template will be written to `tools/release_templates/`
If you are using `oshinko-deploy.sh`, you can specify the new
template as the value for the `-t` option as described below.

### Checking the default spark image for oshinko-rest and oshinko-web

If you want to see what spark image will be used by oshinko, running an
oshinko-rest image like this will print the image default:

    $ docker run --rm radanalyticsio/oshinko-rest oshinko-rest-server --info

For oshinko-webui do this:

    $ docker run --rm radanalyticsio/oshinko-webui /usr/src/app/info.sh

## Sample script to deploy the oshinko application with existing images

The `tools/oshinko-deploy.sh` script can deploy the oshinko suite into an existing
OpenShift deployment or it can start an all-in-one docker OpenShift on the
host. It will pull the latest oshinko-web and oshinko-rest upstream images
from the radanalyticsio organization. It can also be configured to use alternate
images, for more information see the script help text.

**Example all-in-one deployment**

    $ ./tools/oshinko-deploy.sh -d

This will start an OpenShift all-in-one cluster with the `oc cluster up`
command on the host, then it will deploy the oshinko suite into the
`myproject` project as user `developer`. It will apply the default route
url specified by OpenShift.

**Example deployment on remote cluster**

    $ ./tools/oshinko-deploy.sh -c https://10.0.1.100:8443 \
                          -u bob \
                          -p bobsproject \
                          -o bobsoshinko.10.0.1.100.xip.io

This will deploy oshinko into the OpenShift cluster on the 10.0.1.100 host,
in the `bobsproject` project as user `bob`. It will apply the route url
`bobsoshinko.10.0.1.100.xip.io` to the oshinko web console.

### A note on permissions

The all-in-one deployment requires that the user running the script has
permission to issue docker commands. If docker is not configured to
allow non-root access, you will need to invoke this script using `sudo`
or as the `root` user for an all-in-one deployment.

## Sample scripts for interacting with oshinko-rest using curl

The `tools/scripts` subdirectory contains several scripts that
interact with oshinko-rest using curl. These scripts may be used
as is or serve as examples.

## Development notes

This project is using an OpenAPI definition for its API, located at
`api/swagger.yaml`. The code in this project has been mostly generated by
using the tooling from [go-swagger](https://github.com/go-swagger/go-swagger).

Due to the generated nature of this codebase, there are a few places to
investigate when looking to add functionality:

* `restapi/configure_oshinko_rest.go`, this file is generated by the go-swagger
  tooling, but is deemed safe to edit as the entry point for endpoint handlers.

* `handlers/*`, this package has been added to help separate the endpoint
  handler functions. New handlers, or handler functionality, should be added
  here.

### Requirements for building

* go-swagger, https://github.com/go-swagger/go-swagger (only needed for
  validating the api file, or regenerating the client/server files)

## Running oshinko-rest as a Docker container

To run the rest server as a container, use the `make image` target to build a
container image. With the image built, it can be started from the command
line using a syntax similar to:

    $ docker run --rm -it -p 8080:8080 oshinko-rest

This will start the server listening on `0.0.0.0:8080`, which is the default
option. To customize this behavior, the environment variables
`OSHINKO_SERVER_HOST` and `OSHINKO_SERVER_PORT` can be specified to the
`docker run` command to specify an address and port, respectively.

## Running oshinko-rest outside of OpenShift

It's possible to run oshinko-rest locally; this can be a
big help during development and debugging.

To do this make a file to setup the env, for instance:

    $ more oshinko-env
    export GOPATH=/home/oshinko-fork/
    export OSHINKO_CLUSTER_NAMESPACE="spark"
    export OSHINKO_KUBE_CONFIG="/home/user/.kube/config"
    export OSHINKO_CLUSTER_IMAGE=

This is a convenience that sets the GOPATH, tells oshinko-rest what openshift
project it will be running in, gives it a path to a valid kube config file
that it will use for communication with the openshift server, and optionally
tells it what docker image from an accessible repo to use for creating spark clusters.
(These env values are usually handled via the template that launches
oshinko-rest in openshift).

**Note**, you must also log in to the appropriate openshift user
account before running oshinko-rest with this setup:

    $ oc login -u myuser
    $ source oshinko-env

Now you're ready to run:

    $ cd /path/to/oshinko_binary
    $ oshinko-rest

## Debugging

### Logs

Basic log-level debugging can be improved by running the server with the
debug option enabled (`--debug` or `-d`). The server can print all
interactions with OpenShift and Kubernetes by setting the `--loglevel`
command line flag. This flag acts in a similar manner as the `oshinko-cli`
and `oc` applications.

To add debug-only logs to your code, please use the `Debug` function in the
logging helper package.

```
import (
    "github.com/radanalyticsio/oshinko-cli/rest/helpers/logging"
)

func MyFunc() {
    ...

    logging.Debug("a thing happened!")

    ...
}
```
### Delve

Delve can be found at https://github.com/derekparker/delve with
instructions for building/installing.

Assuming that delve is installed on your local system, and you are
set up to run oshinko-rest locally as described above in
[Running outside of openshift](#running-outside-of-openshift), here is a simple
overview of how to get going with delve to debug oshinko-rest.

Delve can handle vendoring but you must set the flag in the env:

    $ export GO15VENDOREXPERIMENT=1

Set up your env as you would for a local run and navigate to the directory
containing the *main.go* file for oshinko-rest, for example:

    $ oc login -u myuser
    $ source oshinko-env
    $ cd /home/oshinko-rest/src/github.com/radanalyticsio/oshinko-cli/rest/cmd/oshinko-rest-server
    $ ls
    main.go

Simply invoke delve in the directory to start debugging:

    $ dlv debug
    Type 'help' for list of commands.
    (dlv) continue
    2016/07/12 14:45:50 Serving oshinko rest at http://127.0.0.1:38016

To pass arguments to oshinko-rest, the invocation will look something like:

    $ dlv debug -- --port=32344

Breakpoints can be set by file:line or by package.function, as long as it
is unambiguous. For example:

    (dlv) break  /home/oshinko-rest/src/github.com/radanalyticsio/oshinko-cli/rest/handlers/server.go:12
    Breakpoint 1 set at 0x5f3ebc for github.com/radanalyticsio/oshinko-cli/rest/handlers.ServerResponse() /home/oshinko-rest/src/github.com/radanalyticsio/oshinko-cli/rest/handlers/server.go:12

    (dlv) break main.main
    Breakpoint 1 set at 0x4020eb for main.main() ./main.go:17

That's it! Use **help** for commands like (c)ontinue, (s)tep, (n)ext, etc
